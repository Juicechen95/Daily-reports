# self-learning


# Plan

发现一个重要问题，到目前为止，我做的Imagenet上的试验都是gbsparsity = 0.5的。。。。。

1.设计多种GCM，在小的imagenet-100上调参

l:lambda,  t:theta,   n 每n个kernel进行循环，大变方向theta值

lr = 0.01

|baseline_resent18|acc at epoch 45|acc at epoch 80|
|--------|:-----------------:|------------:|
|train|78.89|86.75|
|test|76.40|78.48|
|gap|2.49|8.27|



fully-fixed lr=0.04, decay each 30 epochs

|mode| tig|tig1|tig2|tig3|tig4|tig5|tig6|tig7|
| ---------- |:----------:|:-----------:|:-------:|:---------:|:-------:|:---------:|:---------:|:---------:|
|mode|l=3,t+=i,n=4（原始的对比组）|l=3,t+=3i,n=4|l=3+i,t+=i,n=4|l=5,t+=i,n=4|l=2+i,t+=3i,n=4 && l=3+i,t+=3i,n=4|l=3+i,t+=3i,n=4|l=3+i && 4-i,t,n=4|l=2+i,t+=i,n=4 && l=3+i,t+=i,n=4|
|train acc at epoch 45|76.03|76.95|78.76|76.81|77.99|78.53||
|test acc at epoch 45|73.38|73.84|75|72.10|75.02|74.58||
|gap|2.65|3.11|3.76|4.71|2.97|3.95||
|analysis|
| ---------- |:----------:|:-----------:|:-------:|:---------:|:-------:|:---------:|
|train acc at epoch 80|81.60|82.19|84.27||83.67|84.01|83.66|
|train acc at epoch 80|74.12|74.48|75.54||75.16|75.61|75.34|
|gap|7.48|7.71|8.73||8.51|8.4|8.32|
|analysis|从长期曲线来看，tig2是最好的，tig4&tig5都差不多|说明改变lambda是有效的，而theta变成3i不如i的好|||


fully-fixed lr=0.05

|mode| tig|tig1|tig2|tig3|tig4|tig5|
| ---------- |:----------:|:-----------:|:-------:|:---------:|:-------:|:---------:|
|mode|l=3,t+=i,n=4（原始的对比组）|l=3,t+=3i,n=4|l=3+i,t+=i,n=4|l=5,t+=i,n=4|l=2+i,t+=3i,n=4 && l=3+i,t+=3i,n=4|l=3+i,t+=3i,n=4|

semi-fixed lr = 0.08

|mode| tig|tig1|tig2|tig3|tig4|tig5|
| ---------- |:----------:|:-----------:|:-------:|:---------:|:-------:|:---------:|
|mode|l=3,t+=i,n=4（原始的对比组）|l=3,t+=3i,n=4|l=3+i,t+=i,n=4|l=5,t+=i,n=4|l=2+i,t+=3i,n=4 && l=3+i,t+=3i,n=4|l=3+i,t+=3i,n=4|
|train acc at epoch 80|87.01||86.90||86.85|87.06|
|train acc at epoch 80|78.86||78.54||78.58|78.64|
|gap|8.15||8.36||8.07|8.42|
|analysis|

总结：

fully-fixed 下，tig2,4,5等可以比tig更好，但semi-fixed 模式，没有明显区别。。。
# Done



# Next



# Problems
